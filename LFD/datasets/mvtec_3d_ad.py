import os
import PIL
import math
import torch
from torchvision import transforms

_CLASSNAMES = ["bagel", "cable_gland", "carrot", "cookie", "dowel",
            "foam", "peach", "potato", "rope", "tire"]

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

class MVTec3dTrainDataset(torch.utils.data.Dataset):
    """MVTec3d Train Dataset
    Args:
        original_path (str): original dataset path
        generated_path (str): generated dataset path
        classname (str): class name
        resize (int): image resize
    Returns:
        dict: {'img': image, 'mask': mask}
    """
    def __init__(self, generated_path, original_path, classname, resize):
        super().__init__()
        self.generated_path = generated_path  
        self.original_path = original_path 
        self.classname = [classname] if classname is not None else _CLASSNAMES
        self.image_all_list, self.mask_all_list = self.get_image_data()
        self.transform_img = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
        ])
        self.transform_mask = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
        ])
        self.imagesize = (3, resize, resize)

    def __getitem__(self, idx):
        image_path = self.image_all_list[idx]
        mask_path = self.mask_all_list[idx]
        image = PIL.Image.open(image_path).convert("RGB")
        image = self.transform_img(image)
        if mask_path is not None:
            mask = PIL.Image.open(mask_path)
            mask = self.transform_mask(mask).squeeze(0)  # shape: [H, W]
        else:
            mask = torch.zeros((image.shape[1], image.shape[2]))  # shape: [H, W]
        return {"img": image, "mask": mask}

    def __len__(self):
        return len(self.image_all_list)

    def get_image_data(self):
        """Get image and mask path list (for the train set, use all generated anomaly data and the first 1/3 anomaly data in the original test set and all "good" data in the original train set)
        Returns:
            image_all_list (list): image path list
            mask_all_list (list): mask path list 
        """
        image_all_list = []
        mask_all_list = []
        # 1. Use the data generated by SeaS
        for class_name in self.classname:
            class_dir = os.path.join(self.generated_path, class_name)
            if not os.path.isdir(class_dir):
                continue
            for subtype in os.listdir(class_dir):
                subtype_dir = os.path.join(class_dir, subtype)
                image_dir = os.path.join(subtype_dir, 'image')
                mask_dir = os.path.join(subtype_dir, 'mask')
                if not (os.path.isdir(image_dir) and os.path.isdir(mask_dir)):
                    continue
                image_list = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
                mask_list = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
                assert len(image_list) == len(mask_list)
                image_all_list.extend(image_list)
                mask_all_list.extend(mask_list)
        # 2. Use the first 1/3 anomaly data in the original test set as the train set
        for class_name in self.classname:
            test_dir = os.path.join(self.original_path, class_name, 'test')
            if not os.path.isdir(test_dir):
                continue
            for subtype in os.listdir(test_dir):
                if subtype == 'good':
                    continue
                subtype_dir = os.path.join(test_dir, subtype)
                rgb_dir = os.path.join(subtype_dir, 'rgb')
                gt_dir = os.path.join(subtype_dir, 'gt')
                if not (os.path.isdir(rgb_dir) and os.path.isdir(gt_dir)):
                    continue
                rgb_list = sorted([os.path.join(rgb_dir, f) for f in os.listdir(rgb_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
                gt_list = sorted([os.path.join(gt_dir, f) for f in os.listdir(gt_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
                assert len(rgb_list) == len(gt_list)
                n = len(rgb_list)
                split_idx = n // 3
                image_all_list.extend(rgb_list[:split_idx])
                mask_all_list.extend(gt_list[:split_idx])
        # 3. Use all normal images in the original dataset train/good
        for class_name in self.classname:
            train_good_dir = os.path.join(self.original_path, class_name, 'train', 'good', 'rgb')
            if not os.path.isdir(train_good_dir):
                continue
            good_list = sorted([os.path.join(train_good_dir, f) for f in os.listdir(train_good_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
            image_all_list.extend(good_list)
            mask_all_list.extend([None] * len(good_list))  # good sample mask is all 0
        # print(f"[DEBUG] {self.classname}: loaded {len(image_all_list)} images")
        return image_all_list, mask_all_list


class MVTec3dTestDataset(torch.utils.data.Dataset):
    """MVTec3d Test Dataset
    Args:
        source (str): original dataset path
        classname (str): class name
        resize (int): image resize
        train (bool): train or test
    Returns:
        dict: {'img': image, 'mask': mask, 'image_path': image_path}
    """
    def __init__(self, source, classname, resize=256):
        super().__init__()
        self.original_path = source
        self.classname = [classname] if classname is not None else _CLASSNAMES
        self.image_all_list, self.mask_all_list = self.get_image_data()
        self.transform_img = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
        ])
        self.transform_mask = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
        ])
        self.imagesize = (3, resize, resize)

    def __getitem__(self, idx):
        image_path = self.image_all_list[idx]
        mask_path = self.mask_all_list[idx]
        image = PIL.Image.open(image_path).convert("RGB")
        image = self.transform_img(image)
        if mask_path is not None:
            mask = PIL.Image.open(mask_path)
            mask = self.transform_mask(mask).squeeze(0)
        else:
            mask = torch.zeros((image.shape[1], image.shape[2]))
        return {"img": image, "mask": mask, "image_path": image_path}

    def __len__(self):
        return len(self.image_all_list)

    def get_image_data(self):
        """Get image and mask path list (for the test set, use the last 2/3 of the anomaly data and all 'good' data from the original test set)
        Returns:
            image_all_list (list): image path list
            mask_all_list (list): mask path list
            class_labels_list (list): class label list (good: 0, anomaly: 1)
        """
        image_all_list = []
        mask_all_list = []
        # 1.  Use the last 2/3 anomaly data in the original test set
        for class_name in self.classname:
            test_dir = os.path.join(self.original_path, class_name, 'test')
            if not os.path.isdir(test_dir):
                continue
            for subtype in os.listdir(test_dir):
                if subtype == 'good':
                    continue
                subtype_dir = os.path.join(test_dir, subtype)
                rgb_dir = os.path.join(subtype_dir, 'rgb')
                gt_dir = os.path.join(subtype_dir, 'gt')
                if not (os.path.isdir(rgb_dir) and os.path.isdir(gt_dir)):
                    continue
                rgb_list = sorted([os.path.join(rgb_dir, f) for f in os.listdir(rgb_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
                gt_list = sorted([os.path.join(gt_dir, f) for f in os.listdir(gt_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
                assert len(rgb_list) == len(gt_list)
                n = len(rgb_list)
                split_idx = n // 3
                image_all_list.extend(rgb_list[split_idx:])
                mask_all_list.extend(gt_list[split_idx:])
        # 2. Use all all 'good' data from the original test set
        for class_name in self.classname:
            test_good_dir = os.path.join(self.original_path, class_name, 'test', 'good', 'rgb')
            if not os.path.isdir(test_good_dir):
                continue
            good_list = sorted([os.path.join(test_good_dir, f) for f in os.listdir(test_good_dir) if f.lower().endswith('.png') or f.lower().endswith('.jpg')])
            image_all_list.extend(good_list)
            mask_all_list.extend([None] * len(good_list))
        
        return image_all_list, mask_all_list
    
def mvtec3d_train_dataloader(cfg, class_name=None):
    """MVTec3d Train DataLoader
    Args:
        cfg (dict): configuration file
    Returns:
        train_dataloader (torch.utils.data.DataLoader): train dataloader
    """
    train_dataset = MVTec3dTrainDataset(
        original_path=cfg['datasets']['data_path'],
        generated_path=cfg['datasets']['generated_data_path'],
        classname=class_name,
        resize=cfg['datasets']['img_resize']
    )
    print(f"train dataset length: {len(train_dataset)}")
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=cfg['training']['batch_size'],
        shuffle=True,
        num_workers=cfg['training']['num_workers']
    )
    return train_loader

def mvtec3d_test_dataloader(cfg, class_name=None):
    """MVTec3d Test DataLoader
    Args:
        cfg (dict): configuration file
        train (bool): train or test
    Returns:
        test_dataloader (torch.utils.data.DataLoader): test dataloader
    """
    test_dataset = MVTec3dTestDataset(
        source=cfg['datasets']['data_path'],
        classname=class_name,
        resize=cfg['datasets']['img_resize']
    )
    test_loader = torch.utils.data.DataLoader(
        test_dataset,
        batch_size=1,
        shuffle=False,
        num_workers=4
    )
    return test_loader
