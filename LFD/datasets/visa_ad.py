import os
from enum import Enum
import PIL
from PIL import Image
import torch
from torchvision import transforms
import random
import math

_CLASSNAMES = ['candle', 'capsules', 'cashew', 'chewinggum', 'fryum',
            'macaroni1', 'macaroni2', 'pcb1', 'pcb2', 'pcb3', 
            'pcb4', 'pipe_fryum']


IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]

class DatasetSplit(Enum):
    TRAIN = "train"
    VAL = "val"
    TEST = "test"

class VisATrainDataset(torch.utils.data.Dataset):
    """VisA Train Dataset
    Args:
        original_path (str): original dataset path
        generated_path (str): generated dataset path
        classname (str): class name
        resize (int): image resize
    Returns:
        dict: {'img': image, 'mask': mask}
    """
    def __init__(self, original_path, generated_path, classname, resize):
        super().__init__()
        self.original_path = original_path
        self.generated_path = generated_path
        self.classname = [classname] if classname is not None else _CLASSNAMES
        self.image_all_list, self.mask_all_list = self.get_image_data()
        self.transform_img = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
        ])
        self.transform_mask = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
        ])
        self.imagesize = (3, resize, resize)

    def __getitem__(self, idx):
        image_path = self.image_all_list[idx]
        mask_path = self.mask_all_list[idx]
        image = Image.open(image_path).convert("RGB")
        image = self.transform_img(image)
        if mask_path is not None:
            mask = Image.open(mask_path)
            mask = self.transform_mask(mask)
        else:
            mask = torch.zeros([1, *image.size()[1:]])
        return {"img": image, "mask": mask[0]}

    def __len__(self):
        return len(self.image_all_list)

    def get_image_data(self):
        """Get image and mask path list (for the train set, use all generated anomaly data and the first 1/3 anomaly data in the original test set and all "good" data in the original train set)
        Returns:
            image_all_list (list): image path list
            mask_all_list (list): mask path list 
        """
        image_all_list = []
        mask_all_list = []

        for class_name in self.classname:
            # 1. Use the data generated by SeaS
            generated_class_dir = os.path.join(self.generated_path, class_name)
            if os.path.isdir(generated_class_dir):
                anomaly_types = os.listdir(generated_class_dir)
                for anomaly_type in anomaly_types:
                    generated_dir = os.path.join(generated_class_dir, anomaly_type)
                    generated_image_dir = os.path.join(generated_dir, 'image')
                    generated_mask_dir = os.path.join(generated_dir, 'mask')
                    if not (os.path.isdir(generated_image_dir) and os.path.isdir(generated_mask_dir)):
                        continue
                    generated_image_list = sorted([
                        os.path.join(generated_image_dir, f)
                        for f in os.listdir(generated_image_dir)
                        if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                    ])
                    generated_mask_list = sorted([
                        os.path.join(generated_mask_dir, f)
                        for f in os.listdir(generated_mask_dir)
                        if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                    ])
                    assert len(generated_image_list) == len(generated_mask_list), f"{class_name}-{anomaly_type} data load error..."
                    image_all_list.extend(generated_image_list)
                    mask_all_list.extend(generated_mask_list)
           
            # 2. Use the first 1/3 anomaly data in the original test set 
            gt_dir = os.path.join(self.original_path, class_name, 'ground_truth')
            if os.path.isdir(gt_dir):
                anomaly_types = os.listdir(gt_dir)
                for anomaly_type in anomaly_types:
                    image_path_dir = os.path.join(self.original_path, class_name, 'test', anomaly_type)
                    mask_path_dir = os.path.join(gt_dir, anomaly_type)
                    if not (os.path.isdir(image_path_dir) and os.path.isdir(mask_path_dir)):
                        continue
                    image_path_list = sorted([
                        os.path.join(image_path_dir, f)
                        for f in os.listdir(image_path_dir)
                        if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                    ])
                    mask_path_list = sorted([
                        os.path.join(mask_path_dir, f)
                        for f in os.listdir(mask_path_dir)
                        if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                    ])
                    assert len(image_path_list) == len(mask_path_list), f"{class_name}-{anomaly_type} data load error..."
                    train_num = math.floor(len(image_path_list) / 3)
                    if train_num > 0:
                        image_all_list.extend(image_path_list[:train_num])
                        mask_all_list.extend(mask_path_list[:train_num])
             # 3. Use all 'good' data from the original train set
            normal_train_dir = os.path.join(self.original_path, class_name, 'train', 'good')
            if os.path.isdir(normal_train_dir):
                normal_train_list = sorted([
                    os.path.join(normal_train_dir, f)
                    for f in os.listdir(normal_train_dir)
                    if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                ])
                image_all_list.extend(normal_train_list)
                mask_all_list.extend([None] * len(normal_train_list))
       
        assert(len(image_all_list) == len(mask_all_list))
        return image_all_list, mask_all_list


class VisATestDataset(torch.utils.data.Dataset):
    """VisA Test Dataset
    Args:
        source (str): original dataset path
        classname (str): class name
        resize (int): image resize
        train (bool): train or test
    Returns:
        dict: {'img': image, 'mask': mask, 'image_path': image_path}
    """
    def __init__(self, source, classname, resize=256):
        super().__init__()
        self.test_path = source
        self.classnames_to_use = [classname] if classname is not None else _CLASSNAMES
        self.image_all_list, self.mask_all_list, self.class_labels_list = self.get_image_data()
        self.transform_img = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        self.transform_mask = transforms.Compose([
            transforms.Resize((resize,resize)),
            transforms.ToTensor(),
        ])
        self.imagesize = (3, resize, resize)

    def __getitem__(self, idx):
        image_path = self.image_all_list[idx]
        mask_path = self.mask_all_list[idx]
        label = torch.tensor(self.class_labels_list[idx])
        image = Image.open(image_path).convert("RGB")
        image = self.transform_img(image)
        if mask_path is not None:
            mask = Image.open(mask_path)
            mask = self.transform_mask(mask)
        else:
            mask = torch.zeros([1, *image.size()[1:]])

        return {"img": image, "mask": mask[0], 'image_path': image_path}


    def __len__(self):
        return len(self.image_all_list)

    def get_image_data(self):
        """Get image and mask path list (for the test set, use the last 2/3 of the anomaly data and all 'good' data from the original test set)
        Returns:
            image_all_list (list): image path list
            mask_all_list (list): mask path list
            class_labels_list (list): class label list (good: 0, anomaly: 1)
        """
        image_all_list = []
        mask_all_list = []
        class_labels_list = []
        
        for classname in self.classnames_to_use:
            class_path = os.path.join(self.test_path, classname)
            # 1. Use the last 2/3 anomaly data in the original test set
            gt_dir = os.path.join(class_path, 'ground_truth')
            if os.path.isdir(gt_dir):
                anomaly_types = os.listdir(gt_dir)
                for anomaly_type in anomaly_types:
                    image_path_dir = os.path.join(class_path, 'test', anomaly_type)
                    mask_path_dir = os.path.join(gt_dir, anomaly_type)
                    if not (os.path.isdir(image_path_dir) and os.path.isdir(mask_path_dir)):
                        continue
                    image_path_list = sorted([
                        os.path.join(image_path_dir, f)
                        for f in os.listdir(image_path_dir)
                        if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                    ])
                    mask_path_list = sorted([
                        os.path.join(mask_path_dir, f)
                        for f in os.listdir(mask_path_dir)
                        if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                    ])
                    assert len(image_path_list) == len(mask_path_list), f"{classname}-{anomaly_type} data load error..."
                    train_num = math.floor(len(image_path_list) / 3)
                    if train_num < len(image_path_list):
                        image_all_list.extend(image_path_list[train_num:])
                        mask_all_list.extend(mask_path_list[train_num:])
                        class_labels_list.extend([1] * (len(image_path_list[train_num:])))
            # 2. Use all all 'good' data from the original test set
            good_dir = os.path.join(class_path, 'test', 'good')
            if os.path.isdir(good_dir):
                good_list = sorted([
                    os.path.join(good_dir, f)
                    for f in os.listdir(good_dir)
                    if f.lower().endswith('.png') or f.lower().endswith('.jpg')
                ])
                image_all_list.extend(good_list)
                mask_all_list.extend([None] * len(good_list))
                class_labels_list.extend([0] * len(good_list))
       
        return image_all_list, mask_all_list, class_labels_list


def visa_train_dataloader(cfg, class_name=None):
    """VisA Train DataLoader
    Args:
        cfg (dict): configuration file
    Returns:
        train_dataloader (torch.utils.data.DataLoader): train dataloader
    """
    train_dataset = VisATrainDataset(original_path=cfg['datasets']['data_path'],
                                     generated_path=cfg['datasets']['generated_data_path'],
                                     classname=class_name, 
                                     resize=cfg['datasets']['img_resize'])

    print(f"train dataset length: {len(train_dataset)}")

    train_loader = torch.utils.data.DataLoader(train_dataset, 
                                               batch_size=cfg['training']['batch_size'], 
                                               shuffle=True, 
                                               num_workers=cfg['training']['num_workers'])
    return train_loader


def visa_test_dataloader(cfg, dataset_name=None, class_name=None):
    """VisA Test DataLoader
    Args:
        cfg (dict): configuration file
        train (bool): train or test
    Returns:
        test_dataloader (torch.utils.data.DataLoader): test dataloader
    """
    test_dataset = VisATestDataset(source=cfg['datasets']['data_path'],
                                    classname=class_name, 
                                    resize=cfg['datasets']['img_resize'])
    test_loader = torch.utils.data.DataLoader(test_dataset, 
                                              batch_size=1, 
                                              shuffle=False, 
                                              num_workers=4)
    return test_loader