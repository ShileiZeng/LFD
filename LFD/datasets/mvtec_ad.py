import os
from PIL import Image
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
import torch
from torchvision import transforms
import math

_CLASSNAMES = ["bottle", "cable", "capsule", "carpet", "grid",
            "hazelnut", "leather", "metal_nut", "pill", "screw",
            "tile", "toothbrush", "transistor", "wood", "zipper"]

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD = [0.229, 0.224, 0.225]


class MVTecTrainDataset(torch.utils.data.Dataset):
    """MVTec Train Dataset
    Args:
        original_path (str): original dataset path
        generated_path (str): generated dataset path
        classname (str): class name
        resize (int): image resize
    Returns:
        dict: {'img': image, 'mask': mask}
    """
    def __init__(self, original_path, generated_path, classname, resize):
        super().__init__()
        self.original_path = original_path
        self.generated_path = generated_path
        self.classname = [classname] if classname is not None else _CLASSNAMES
        self.image_all_list, self.mask_all_list = self.get_image_data()
        self.transform_img = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
            transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)
        ])
        self.transform_mask = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
        ])
        self.imagesize = (3, resize, resize)


    def __getitem__(self, idx):
        image_path = self.image_all_list[idx]
        mask_path = self.mask_all_list[idx]
        image = Image.open(image_path).convert("RGB")
        image = self.transform_img(image)
        if mask_path is not None:
            mask = Image.open(mask_path)
            mask = self.transform_mask(mask)
        else:
            mask = torch.zeros([1, *image.size()[1:]])
        return {"img": image, "mask": mask[0]}

    def __len__(self):
        return len(self.image_all_list)

    def get_image_data(self):
        """Get image and mask path list (for the train set, use all generated anomaly data and the first 1/3 anomaly data in the original test set and all "good" data in the original train set)
        Returns:
            image_all_list (list): image path list
            mask_all_list (list): mask path list 
        """
        image_all_list = []
        mask_all_list = []

        for class_name in self.classname:
            #1.Use the data generated by SeaS
            anomaly_types = os.listdir(os.path.join(self.generated_path, class_name))
            for anomaly_type in anomaly_types:
                generated_dir = os.path.join(self.generated_path, class_name, anomaly_type)
                generated_image_dir = os.path.join(generated_dir, 'image')
                generated_mask_dir = os.path.join(generated_dir, 'mask')
                generated_image_list = sorted([file for file in os.listdir(generated_image_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')])
                generated_image_list = [os.path.join(generated_image_dir, file) for file in generated_image_list]
                generated_mask_list = sorted([file for file in os.listdir(generated_mask_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')])
                generated_mask_list = [os.path.join(generated_mask_dir, file) for file in generated_mask_list]
                assert len(generated_image_list)==len(generated_mask_list), f"{class_name}-{anomaly_type} data load error..."
                image_all_list.extend(generated_image_list)
                mask_all_list.extend(generated_mask_list)

            # 2. Use the first 1/3 anomaly data in the original test set 
            anomaly_types = os.listdir(os.path.join(self.original_path, class_name, 'ground_truth'))
            # anomaly_types = [t for t in os.listdir(os.path.join(self.original_path, class_name, 'ground_truth')) if t != 'good']
            for anomaly_type in anomaly_types:
                image_path_dir = os.path.join(self.original_path, class_name, 'test', anomaly_type)
                image_path_list = [file for file in os.listdir(image_path_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')]
                image_path_list = [os.path.join(image_path_dir, file) for file in sorted(image_path_list)]
                mask_path_dir = os.path.join(self.original_path, class_name, 'ground_truth', anomaly_type)
                mask_path_list = [file for file in os.listdir(mask_path_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')]
                mask_path_list = [os.path.join(mask_path_dir, file) for file in sorted(mask_path_list)]
                train_num = math.floor(len(image_path_list)/3)
                image_all_list.extend(image_path_list[:train_num])
                mask_all_list.extend(mask_path_list[:train_num])

            # 3. all "good" data in the original train set
            normal_train_dir = os.path.join(self.original_path, class_name, 'train', 'good')
            normal_train_list = [file for file in os.listdir(normal_train_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')]
            normal_train_list = [os.path.join(normal_train_dir, file) for file in normal_train_list]
            image_all_list.extend(normal_train_list)
            mask_all_list.extend([None]*len(normal_train_list))
            
        assert(len(image_all_list) == len(mask_all_list))
        return image_all_list, mask_all_list


class MVTecTestDataset(torch.utils.data.Dataset):
    """MVTec Test Dataset
    Args:
        source (str): original dataset path
        classname (str): class name
        resize (int): image resize
        train (bool): train or test
    Returns:
        dict: {'img': image, 'mask': mask, 'image_path': image_path}
    """
    def __init__(self, source, classname, resize=256):
        super().__init__()
        self.test_path = source
        self.classnames_to_use = [classname] if classname is not None else _CLASSNAMES

        self.image_all_list, self.mask_all_list, self.class_labels_list = self.get_image_data()

        self.transform_img = transforms.Compose([
            transforms.Resize((resize, resize)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        self.transform_mask = transforms.Compose([
            transforms.Resize((resize,resize)),
            transforms.ToTensor(),
        ])
        self.imagesize = (3, resize, resize)

    def __getitem__(self, idx):
        image_path = self.image_all_list[idx]
        mask_path = self.mask_all_list[idx]
        label = torch.tensor(self.class_labels_list[idx])
        image = Image.open(image_path).convert("RGB")
        image = self.transform_img(image)
        if mask_path is not None:
            mask = Image.open(mask_path)
            mask = self.transform_mask(mask)
        else:
            mask = torch.zeros([1, *image.size()[1:]])

        return {"img": image, "mask": mask[0], 'image_path': image_path}


    def __len__(self):
        return len(self.image_all_list)

    def get_image_data(self):
        """Get image and mask path list (for the test set, use the last 2/3 of the anomaly data and all 'good' data from the original test set)
        Returns:
            image_all_list (list): image path list
            mask_all_list (list): mask path list
            class_labels_list (list): class label list (good: 0, anomaly: 1)
        """
        image_all_list = []
        mask_all_list = []
        class_labels_list = []
        for classname in self.classnames_to_use:
            class_path = os.path.join(self.test_path, classname)
            # 1. Use the last 2/3 anomaly data in the original test set
            anomaly_types = os.listdir(os.path.join(self.test_path, classname, 'ground_truth'))
            for anomaly_type in anomaly_types:
                image_path_dir = os.path.join(self.test_path, classname, 'test', anomaly_type)
                image_path_list = [file for file in os.listdir(image_path_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')]
                image_path_list = [os.path.join(image_path_dir, file) for file in sorted(image_path_list)]
                mask_path_dir = os.path.join(self.test_path, classname, 'ground_truth', anomaly_type)
                mask_path_list = [file for file in os.listdir(mask_path_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')]
                mask_path_list = [os.path.join(mask_path_dir, file) for file in sorted(mask_path_list)]
                train_num = math.floor(len(image_path_list)/3)
                image_all_list.extend(image_path_list[train_num:])
                class_labels_list.extend([1]*len(image_path_list[train_num:])) 
                mask_all_list.extend(mask_path_list[train_num:])
                
            # 2. Use all all 'good' data from the original test set
            anomaly_types = os.listdir(os.path.join(class_path, 'test'))
            for anomaly_type in anomaly_types:
                if anomaly_type == 'good':
                    image_path_dir = os.path.join(class_path, 'test', anomaly_type)
                    image_path_list = [file for file in os.listdir(image_path_dir) if file.lower().endswith('.png') or file.lower().endswith('.jpg')]
                    image_path_list = [os.path.join(image_path_dir, file) for file in image_path_list]
                    image_path_list = sorted(image_path_list)
                    # If the anomaly type is 'good', the mask path is None
                    mask_path_list = [None] * len(image_path_list)                    
                    # Check if the number of images and masks are consistent
                    assert len(image_path_list)==len(mask_path_list), f"{classname}-{anomaly_type} data load error..."
                    # Save the paths of images, masks, and class labels to the lists
                    image_all_list.extend(image_path_list)
                    mask_all_list.extend(mask_path_list)
                    class_labels_list.extend([0]*len(image_path_list))

        return image_all_list, mask_all_list, class_labels_list


def mvtec_train_dataloader(cfg, class_name=None):
    """MVTec Train DataLoader
    Args:
        cfg (dict): configuration file
    Returns:
        train_dataloader (torch.utils.data.DataLoader): train dataloader
    """
    train_dataset = MVTecTrainDataset(original_path=cfg['datasets']['data_path'],
                                      generated_path=cfg['datasets']['generated_data_path'],
                                      classname=class_name, 
                                      resize=cfg['datasets']['img_resize'])

    print(f"train dataset length: {len(train_dataset)}")

    train_loader = torch.utils.data.DataLoader(train_dataset, 
                                               batch_size=cfg['training']['batch_size'], 
                                               shuffle=True, 
                                               num_workers=cfg['training']['num_workers'])
    return train_loader


def mvtec_test_dataloader(cfg, dataset_name=None, class_name=None):
    """MVTec Test DataLoader
    Args:
        cfg (dict): configuration file
        train (bool): train or test
    Returns:
        test_dataloader (torch.utils.data.DataLoader): test dataloader
    """
    test_dataset = MVTecTestDataset(source=cfg['datasets']['data_path'],
                                    classname=class_name, 
                                    resize=cfg['datasets']['img_resize'])
    test_loader = torch.utils.data.DataLoader(test_dataset, 
                                              batch_size=1, 
                                              shuffle=False, 
                                              num_workers=4)
    return test_loader